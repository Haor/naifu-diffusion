name: test-run

trainer:
  model_url: https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/animesfw.tgz
  # output_path: checkpoint
  init_batch_size: 1
  resolution: 512
  center_crop: false
  gradient_checkpointing: true
  clip_skip: 2
  seed: 1138
  precision: fp32
  half_encoder: false
  use_ema: true
  use_hivemind: false
  use_xformers: false
  
checkpoint:
  monitor: 'train_loss'
  dirpath: checkpoint
  filename: 'sample-nd-epoch{epoch:02d}-val_loss{val/loss:.2f}'
  auto_insert_metric_name: false
  every_n_epochs: 0
  save_top_k: 5
  save_last: true

lightning:
  accelerator: gpu
  devices: -1
  auto_select_gpus: true
  limit_train_batches: 100
  max_epochs: 100
  precision: 32
  gradient_clip_val: 0.0
  auto_scale_batch_size: false
  auto_lr_find: false
  move_metrics_to_cpu: true

arb:
   debug: false
   base_res: [512, 512]
   max_size: [768, 512]
   divisible: 64
   max_ar_error: 4
   min_dim: 256
   dim_limit: 1024

dataset:
  img_path: 
    - "https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/mmk.tgz"
  center_crop: false
  ucg: 0.1
  debug_arb: false
  reload_interval: 10
  num_workers: 3

optimizer:
  name: bitsandbytes.optim.AdamW8bit
  params:
    lr: 5e-6
    weight_decay: 1e-2
    eps: 1e-8

lr_scheduler:
  name: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
  params:
    T_0: 10
    T_mult: 1
    eta_min: 7e-8
    last_epoch: -1

monitor:
  wandb_id: ""
  store_checkpoints: true
