name: test-run

trainer:
  model_url: https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/animesfw.tgz
  init_batch_size: 1
  resolution: 512
  center_crop: false
  gradient_checkpointing: true
  clip_skip: 2
  seed: 1138
  precision: fp32
  half_encoder: true
  use_ema: false
  use_hivemind: true
  use_xformers: false

checkpoint:
  monitor: 'train_loss'
  dirpath: checkpoint
  filename: 'sample-nd-epoch{epoch:02d}-val_loss{train_loss:.2f}'
  auto_insert_metric_name: false
  every_n_epochs: 0
  save_top_k: 2
  save_last: true

hivemind:
  target_batch_size: 1000
  verbose: true
  # initial_peers: ['/ip4/159.223.171.199/tcp/41555/p2p/QmVQks3jCMEyakLtayUxtFXohpunqiMdWuAWpXYo26vrdV']
  run_id: "test-run-1112b"
  host_maddrs: ["/ip4/0.0.0.0/tcp/0", "/ip4/0.0.0.0/udp/0/quic"]
  reuse_grad_buffers: true
  offload_optimizer: false
  matchmaking_time: 260.0
  averaging_timeout: 1200.0
  allreduce_timeout: 1200.0
  load_state_timeout: 1200.0

lightning:
  accelerator: gpu
  devices: -1
  auto_select_gpus: true
  limit_train_batches: 100
  max_epochs: 200
  precision: 32
  log_every_n_steps: 1
  gradient_clip_val: 0
  auto_scale_batch_size: false
  auto_lr_find: false

arb:
  debug: false
  base_res: [512, 512]
  max_size: [768, 512]
  divisible: 64
  max_ar_error: 4
  min_dim: 256
  dim_limit: 1024

dataset:
  img_path: 
    - "https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/mmk.tgz"
  center_crop: false
  ucg: 0.0
  debug_arb: false
  reload_interval: 10
  num_workers: 3

scheduler:
  name: diffusers.DDIMScheduler
  params:
      beta_end: 0.012
      beta_schedule: "scaled_linear"
      beta_start: 0.00085
      clip_sample: false
      num_train_timesteps: 1000
      set_alpha_to_one: false
      steps_offset: 1
      trained_betas: null

optimizer:
  name: torch.optim.AdamW
  params:
    lr: 5e-6
    weight_decay: 1e-2
    eps: 1e-8

lr_scheduler:
  name: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
  params:
    T_0: 10
    T_mult: 1
    eta_min: 7e-8
    last_epoch: -1

monitor:
  wandb_id: ""
  store_checkpoints: true

experiment:
  tokenizer: transformers.CLIPTokenizer
  encoder: transformers.CLIPTextModel